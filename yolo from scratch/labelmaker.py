# -*- coding: utf-8 -*-
"""labelmaker.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qGXdE9c0AY5SIYWhQ3OGTWO2-o4yfGhz
"""

class Label():
    def __init__(self, class_num, topleftx = 0, toplefty = 0, bottomrightx = 0, bottomrighty = 0, image_x = 0, image_y = 0, mid = False):
      self.class_num = class_num
      if mid:
        self.x1 = ((bottomrightx - topleftx)/2 + topleftx)/image_x #midx
        self.y1 = ((bottomrighty - toplefty)/2 + toplefty)/image_y #midy
        self.x2 = (bottomrightx - topleftx)/image_x # width
        self.y2 = (bottomrighty - toplefty)/image_y #length
      else:
        self.x1 = topleftx
        self.y1 = toplefty
        self.x2 = bottomrightx
        self.y2 = toplefty

        

'''
Very simple algorithm and frankly produced quite large bounding boxes.
Could be replaced with a better algorithm if someone has the time.
'''
def boundingboxcalculator(polygon):
  #take a list of sublists, each sublist has x & y
  minx = min([sublist[0] for sublist in polygon])
  miny = min([sublist[1] for sublist in polygon])
  maxx = max([sublist[0] for sublist in polygon])
  maxy = max([sublist[1] for sublist in polygon])
  return minx, miny, maxx, maxy

'''
Only judges Radiolucent versus Radiopaque + Other. This obviously need to be expanded
in the future.
'''
def analyzeDescription(classifications):
  classes = set()
  for classification in classifications:
    if 'answers' in classification:
      for answer in classification['answers']:
        classes.add(answer['title'])  
    elif 'answer' in classification and classification['answer'] != None:
      classes.add(classification['answer']['title'])
  return 1 if "Radiolucent" in classes else 2

def imagesizeanalysis(im_name):
  from PIL import Image
  import os
  
  im = Image.open(os.path.join('C:\\Users\\EaglesonLabs\\object-detection\\yolo from scratch\\Dataset-YOLO\\Radiographs', im_name))
  width, height = im.size
  return width, height

import os, json
# Open the JSON file and read its contents
with open('C:\\Users\\EaglesonLabs\\object-detection\\yolo from scratch\\expert.json', 'r') as f:
    expert_data = json.load(f)
#NEW RECORDS
all_records = {}
imagex, imagey = imagesizeanalysis(expert_data[0]['External ID'])

for json_obj in expert_data:
  if json_obj['Description'] == 'Within normal limits':
    if json_obj['External ID'] not in all_records:
      all_records[json_obj['External ID']] = []
    all_records[json_obj['External ID']].append(Label(0))
  else:
    defect = analyzeDescription(json_obj['Label']['objects'][0]['classifications'])
    for polygon in json_obj['Label']['objects'][0]['polygons']:
      topleftx, toplefty, bottomrightx, bottomrighty = boundingboxcalculator(polygon)
      if json_obj['External ID'] not in all_records:
        all_records[json_obj['External ID']] = []
      all_records[json_obj['External ID']].append(Label(defect, topleftx, toplefty, bottomrightx, bottomrighty, imagex, imagey, True))

#{'img1.jpg' : [Label1, Label2, ..., Labeln]}
# for each image 
# create a new text file within the label folder
# dump label info into new line for each label

trainCount = 0
testCount = 0
with open("C:\\Users\\\EaglesonLabs\\object-detection\\yolo from scratch\\Dataset-YOLO\\train.csv", 'w') as train:
  with open("C:\\Users\\\EaglesonLabs\\object-detection\\yolo from scratch\\Dataset-YOLO\\test.csv", 'w') as test:
    for key in all_records:
      if trainCount < 400:
        train.write("{},{}.txt\n".format(key, key[:-4]))
        trainCount += 1
      else:
        test.write("{},{}.txt\n".format(key, key[:-4]))
        testCount += 1
      with open(os.path.join("C:\\Users\\\EaglesonLabs\\object-detection\\yolo from scratch\\Dataset-YOLO\\Labels",'{}.txt'.format(key[:-4])), 'w') as output:
        for label in all_records[key]:
          output.write("{}\t{}\t{}\t{}\t{}\t\n".format(label.class_num, label.x1, label.y1, label.x2, label.y2))
print('Train Count: {}'.format(trainCount))
print('Test Count: {}'.format(testCount))